{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature & salinity from a dense feed-forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import torch\n",
    "\n",
    "%load_ext lab_black\n",
    "%load_ext tensorboard\n",
    "\n",
    "PATH_TO_CSV = pathlib.Path(\"dataset.csv\")\n",
    "\n",
    "BANDS = [\n",
    "    \"B1\",\n",
    "    \"B2\",\n",
    "    \"B3\",\n",
    "    \"B4\",\n",
    "    \"B5\",\n",
    "    \"B6\",\n",
    "    \"B7\",\n",
    "    \"B8\",\n",
    "    \"B8A\",\n",
    "    \"B9\",\n",
    "    \"B10\",\n",
    "    \"B11\",\n",
    "    \"B12\",\n",
    "]\n",
    "\n",
    "pd.read_csv(PATH_TO_CSV, index_col=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target: str,\n",
    "        bands: list[str],\n",
    "        train_batch_size: int,\n",
    "        preprocessing: Callable[[pd.DataFrame], pd.DataFrame],\n",
    "        train_frac: float = 0.7,\n",
    "        seed: int = 123456788,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "        self.bands = bands\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.preprocessing = preprocessing\n",
    "        self.train_frac = train_frac\n",
    "        self.seed = seed\n",
    "\n",
    "        assert target not in bands, f\"target {target} should not be present in bands\"\n",
    "        assert self.preprocessing(\n",
    "            pd.DataFrame(torch.rand(10, 4).numpy())\n",
    "        ).shape == torch.Size([10, 4])\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        \"\"\"Read the data and create perform the train/val/test split.\"\"\"\n",
    "        data = pd.read_csv(PATH_TO_CSV, index_col=0)\n",
    "        bands_data = self.preprocessing(data[self.bands])\n",
    "        target_data = self.preprocessing(data[self.target])\n",
    "        full_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(bands_data.values),\n",
    "            torch.from_numpy(target_data.values).view(-1, 1),\n",
    "        )\n",
    "\n",
    "        n_full = len(full_dataset)\n",
    "        n_train = int(n_full * self.train_frac)\n",
    "        n_val = int((n_full - n_train) // 2)  # equal sized validation & test\n",
    "        n_test = n_full - n_train - n_val\n",
    "\n",
    "        (\n",
    "            self.train_dataset,\n",
    "            self.val_dataset,\n",
    "            self.test_dataset,\n",
    "        ) = torch.utils.data.random_split(\n",
    "            full_dataset,\n",
    "            (n_train, n_val, n_test),\n",
    "            generator=torch.Generator().manual_seed(self.seed),\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset, batch_size=self.train_batch_size\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset, batch_size=len(self.val_dataset)\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset, batch_size=len(self.test_dataset)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dims: int,\n",
    "        hidden_dims: list[int],\n",
    "        activation: type[torch.nn.Module],\n",
    "        final_activation: type[torch.nn.Module] = torch.nn.Identity,\n",
    "        out_dims: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        dims = [in_dims, *hidden_dims, out_dims]\n",
    "        activations = [activation for _ in hidden_dims] + [final_activation]\n",
    "\n",
    "        layers = []\n",
    "        for d_in, d_out, f_act in zip(dims[:-1], dims[1:], activations):\n",
    "            layers.append(torch.nn.Linear(d_in, d_out))\n",
    "            layers.append(f_act())\n",
    "\n",
    "        self.network = torch.nn.Sequential(*layers)\n",
    "        self.loss_func = torch.nn.functional.mse_loss\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.view(x.shape[0], -1).float()\n",
    "        return self.network(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True)\n",
    "        return dict(\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=dict(\n",
    "                scheduler=scheduler,\n",
    "                monitor=\"val_loss\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        return self.loss_func(y_pred, y.float())\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        val_loss = self.loss_func(y_pred, y.float())\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        return val_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        return self.loss_func(y_pred, y.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(dm: DataModule, network: DenseNet, dataset: str):\n",
    "    x, y = next(iter(getattr(dm, f\"{dataset}_dataloader\")()))\n",
    "    y = y.view(-1).detach().numpy()\n",
    "    y_pred = network(x).view(-1).detach().numpy()\n",
    "    return y, y_pred\n",
    "\n",
    "\n",
    "def plot(dm: DataModule, network: DenseNet):\n",
    "    # plot entire training set - adjust batch size\n",
    "    tmp = dm.train_batch_size\n",
    "    dm.train_batch_size = len(dm.train_dataset)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(16, 8))\n",
    "\n",
    "    for ax, dataset in zip(axes, (\"train\", \"val\", \"test\")):\n",
    "        y, y_pred = sample(dm, network, dataset)\n",
    "        slope, intercept, r, p, se = scipy.stats.linregress(y, y_pred)\n",
    "\n",
    "        # ax.hexbin(y, y_pred, gridsize=30)\n",
    "        ax.scatter(y, y_pred, s=0.2)\n",
    "        ax.axline(xy1=(0, intercept), slope=slope, color=\"red\", label=f\"r = {r:.2g}\")\n",
    "\n",
    "        ax.set_title(f\"{dataset} : {len(y)} points\")\n",
    "        ax.set_xlabel(\"target\")\n",
    "        ax.set_ylabel(\"prediction\")\n",
    "\n",
    "        ax.set_xlim(min(y.min(), y_pred.min()), max(y.max(), y_pred.max()))\n",
    "        ax.set_ylim(min(y.min(), y_pred.min()), max(y.max(), y_pred.max()))\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.legend()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment: Temperature (SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm = DataModule(\n",
    "    bands=BANDS,\n",
    "    target=\"TEMP\",\n",
    "    train_batch_size=32,\n",
    "    preprocessing=lambda df: (df - df.mean()) / df.std(),  # standardise\n",
    ")\n",
    "network = DenseNet(\n",
    "    in_dims=len(BANDS), hidden_dims=[16, 32, 64, 32, 16], activation=torch.nn.ReLU\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    val_check_interval=10,\n",
    "    progress_bar_refresh_rate=0,\n",
    "    callbacks=[\n",
    "        pl.callbacks.early_stopping.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=10, verbose=False\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "trainer.fit(network, dm)\n",
    "\n",
    "fig = plot(dm, network)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm = DataModule(\n",
    "    bands=BANDS,\n",
    "    target=\"PSAL\",\n",
    "    train_batch_size=32,\n",
    "    preprocessing=lambda df: (df - df.mean()) / df.std(),  # standardise\n",
    ")\n",
    "network = DenseNet(\n",
    "    in_dims=len(BANDS), hidden_dims=[16, 32, 64, 32, 16], activation=torch.nn.ReLU\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    val_check_interval=1,\n",
    "    progress_bar_refresh_rate=0,\n",
    "    callbacks=[\n",
    "        pl.callbacks.early_stopping.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=10, verbose=False\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "trainer.fit(network, dm)\n",
    "\n",
    "fig = plot(dm, network)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
